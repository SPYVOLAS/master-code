# -*- coding: utf-8 -*-
"""CapsNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wCswooaOjFr2AUjqK7bpZv7nk1iR945d
"""

#install the necessary versions of Keras and Tensorflow for running the code
pip install Keras==2.2.4 tensorflow==1.15.0

from google.colab import drive
drive.mount("/content/gdrive")

from keras import layers, models, optimizers
from keras import backend as K
from keras.layers import Input, Conv2D, Dense, Reshape, Layer, Lambda
from keras.models import Model
from keras.utils import to_categorical
from keras import initializers
from keras.optimizers import Adam
from keras.utils.vis_utils import plot_model
import numpy as np
import tensorflow as tf
import pandas as pd
import os
from sklearn.preprocessing import LabelEncoder
import pickle

metadata = pd.read_csv("/content/gdrive/MyDrive/HAM10000_metadata")
test_metadata = pd.read_csv("/content/gdrive/MyDrive/HAM10000_TestMetadata2.csv")
train_metadata = pd.read_csv("/content/gdrive/MyDrive/HAM10000_TrainMetadata.csv")
train_data = "/content/gdrive/MyDrive/train_4"
test_data = "/content/gdrive/MyDrive/val_4"

#converting class values from text to numerical
le = LabelEncoder()
train_metadata["Label"] = le.fit_transform(train_metadata["Class"])

#Getting the path of an image and assign it in a new column to the corrensponding Image ID of train_metadata csv
image_path = []
df = train_metadata.drop(['Class', 'Label'], axis = 1)
for image in df['Image ID']:
  img =os.path.join(train_data, image)
  image_path.append(img)

train_metadata['Path'] = image_path
print(train_metadata.head())

#converting class values from text to numerical
le = LabelEncoder()
test_metadata["Label"] = le.fit_transform(test_metadata["Class"])

#Getting the path of an image and assign it in a new column to the corrensponding Image ID of train_metadata csv
image_path = []
df = test_metadata.drop(['Class', 'Label'], axis = 1)
for image in df['Image ID']:
  img =os.path.join(test_data, image)
  image_path.append(img)

test_metadata['Path'] = image_path
print(test_metadata.head())

output1 = pd.read_pickle("/content/gdrive/MyDrive/TrainMetadata3.pkl")

output2 = pd.read_pickle("/content/gdrive/MyDrive/TestMetadata3.pkl")

from keras import layers, models, optimizers
from keras import backend as K
from keras.layers import Input, Conv2D, Dense, Reshape, Layer, Lambda
from keras.models import Model
from keras.utils import to_categorical
from keras import initializers
from keras.optimizers import Adam
from keras.utils.vis_utils import plot_model
from keras.datasets import mnist
import numpy as np
import tensorflow as tf

#
# The length of the output vector of a capsule is to represent the probability that the entity represented by the capsule
# is present in the current unit. A nonlinear squashing function ensures that
# - short vectors get shrunk to almost zero length and
# - long vectors get shrunk to a length slightly below 1
# this function is designed as
# v_j = \frac{||s_j||^2}{1 + ||s_j||^2 } \frac{s_j}{||s_j||}
#
def squash(output_vector, axis=-1):
    norm = tf.reduce_sum(tf.square(output_vector), axis, keep_dims=True)
    return output_vector * norm / ((1 + norm) * tf.sqrt(norm + 1.0e-10))

#
# This layer takes to input vectors:
#   - the first one is the output of the CapsuleLayer, 'n_calss' arrays
#   - the ground truth vector, an array with a length of 'n_class', with one of the elements is '1', the rests are '0'
#
class MaskingLayer(Layer):
    def call(self, inputs, **kwargs):
        input, mask = inputs
        return K.batch_dot(input, mask, 1)

    def compute_output_shape(self, input_shape):
        *_, output_shape = input_shape[0]
        return (None, output_shape)

#
# construct a conv layer, then reshape and apply squash operation
#
def PrimaryCapsule(n_vector, n_channel, n_kernel_size, n_stride, padding='valid'):
    def builder(inputs):
        output = Conv2D(filters=n_vector * n_channel, kernel_size=n_kernel_size, strides=n_stride, padding=padding)(inputs)
        output = Reshape( target_shape=[-1, n_vector], name='primary_capsule_reshape')(output)
        return Lambda(squash, name='primary_capsule_squash')(output)
    return builder

#
# Traditional Neural Network          Capsule
# scalar in scalar out       -->>     vector in vector out/matrix in matrix out
# back propagation update    -->>     routing update
#
class CapsuleLayer(Layer):
    def __init__(self, n_capsule, n_vec, n_routing, **kwargs):
        super(CapsuleLayer, self).__init__(**kwargs)
        self.n_capsule = n_capsule
        self.n_vector = n_vec
        self.n_routing = n_routing
        self.kernel_initializer = initializers.get('he_normal')
        self.bias_initializer = initializers.get('zeros')

    def build(self, input_shape): # input_shape is a 4D tensor
        _, self.input_n_capsule, self.input_n_vector, *_ = input_shape
        self.W = self.add_weight(shape=[self.input_n_capsule, self.n_capsule, self.input_n_vector, self.n_vector], initializer=self.kernel_initializer, name='W')
        self.bias = self.add_weight(shape=[1, self.input_n_capsule, self.n_capsule, 1, 1], initializer=self.bias_initializer, name='bias', trainable=False)
        self.built = True

    def call(self, inputs, training=None):
        input_expand = tf.expand_dims(tf.expand_dims(inputs, 2), 2)
        input_tiled = tf.tile(input_expand, [1, 1, self.n_capsule, 1, 1])
        input_hat = tf.scan(lambda ac, x: K.batch_dot(x, self.W, [3, 2]), elems=input_tiled, initializer=K.zeros( [self.input_n_capsule, self.n_capsule, 1, self.n_vector]))
        for i in range(self.n_routing): # routing
            c = tf.nn.softmax(self.bias, dim=2)
            outputs = squash(tf.reduce_sum( c * input_hat, axis=1, keep_dims=True))
            if i != self.n_routing - 1:
                self.bias += tf.reduce_sum(input_hat * outputs, axis=-1, keep_dims=True)
        return tf.reshape(outputs, [-1, self.n_capsule, self.n_vector])

    def compute_output_shape(self, input_shape):
        # output current layer capsules
        return (None, self.n_capsule, self.n_vector)

#
# This layer takes 'n_class' arrays as input, outputs an array of size 'n_class',
# each eleemnt in the output array represent the possibility,
# i.e., the last layer in Figure 2.
#
class LengthLayer(Layer):
    def call(self, inputs, **kwargs):
        return tf.sqrt(tf.reduce_sum(tf.square(inputs), axis=-1, keep_dims=False))

    def compute_output_shape(self, input_shape):
        *output_shape, _ = input_shape
        return tuple(output_shape)


#
# margin loss is employed to measure the accuracy of the capsule net,
# in the code below, mean absolute error is used to measure the accuracy of the reconstructed image
#
def margin_loss(y_ground_truth, y_prediction):
    _m_plus = 0.9
    _m_minus = 0.1
    _lambda = 0.5
    L = y_ground_truth * tf.square(tf.maximum(0., _m_plus - y_prediction)) + _lambda * ( 1 - y_ground_truth) * tf.square(tf.maximum(0., y_prediction - _m_minus))
    return tf.reduce_mean(tf.reduce_sum(L, axis=1))


if __name__ == "__main__":

    x_train = np.asarray(output1['Image'].tolist()) 
    x_test = np.asarray(output2['Image'].tolist()) 
    x_train = x_train.astype('float32') / 255.0
    x_test = x_test.astype('float32') / 255.0
    Y_train = train_metadata["Label"]
    Y_test = test_metadata["Label"]
    Y_train_cat = to_categorical(Y_train.astype('float32'))
    Y_test_cat = to_categorical(Y_test.astype('float32'))
    X = np.concatenate((x_train, x_test), axis=0)
    Y = np.concatenate((Y_train_cat, Y_test_cat), axis=0)

    # make model
    input_shape = [28, 28, 3]
    n_class = 7
    n_routing = 3

    # encoder
    x = Input(shape=input_shape)
    conv1 = Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)
    primary_capsule = PrimaryCapsule( n_vector=8, n_channel=32, n_kernel_size=9, n_stride=2)(conv1)
    digit_capsule = CapsuleLayer( n_capsule=n_class, n_vec=16, n_routing=n_routing, name='digit_capsule')(primary_capsule)
    output_capsule = LengthLayer(name='output_capsule')(digit_capsule)

    # decoder
    mask_input = Input(shape=(n_class, ))
    mask = MaskingLayer()([digit_capsule, mask_input])  # two inputs
    dec = Dense(512, activation='relu')(mask)
    dec = Dense(1024, activation='relu')(dec)
    dec = Dense(784, activation='sigmoid')(dec)
    dec = Dense(np.prod(input_shape), activation='sigmoid')(dec)
    dec = Reshape(target_shape = input_shape)(dec)

    model = Model([x, mask_input], [output_capsule, dec])
    plot_model(model, 'capsule.png', show_shapes=True, rankdir='TB')
    model.summary()
    model.compile(optimizer='adam', loss=[margin_loss, 'mae'], metrics= [margin_loss, 'mae', 'accuracy'])

    # train capsule model
    model.fit([X, Y], [Y, X], batch_size=32, epochs=25, validation_split=0.2)

from matplotlib import pyplot as plt

# line 1 points
x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
y1 = [0.3354,0.5044,0.5701,0.5914,0.6112,0.6217,0.6265,0.6330,0.6447,0.6511,
      0.6545,0.6598,0.6689,0.6694,0.6779,0.6853,0.6928,0.6969,0.7005,0.7050,
      0.7173,0.7220,0.7273,0.7304,0.7335]
# plotting the line 1 points 
plt.plot(x1, y1, label = "Training accuracy")
  
# line 2 points
x2 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
y2 = [0.4558,0.5305,0.5743,0.6036,0.6039,0.5943,0.6341,0.5683,0.6506,0.6255,
      0.6385,0.6198,0.6401,0.6325,0.6312,0.6458,0.6607,0.6429,0.6528,0.6423,
      0.6477,0.6439,0.6356,0.6544,0.6689]
# plotting the line 2 points 
plt.plot(x2, y2, label = "Validation accuracy")
  
# naming the x axis
plt.xlabel('Epochs')
# naming the y axis
plt.ylabel('Accuracy')
# giving a title to my graph
plt.title('CapsNet training and validation accuracy')
  
# show a legend on the plot
plt.legend()
  
# function to show the plot
plt.show()

# line 1 points
x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
y1 = [0.3169,0.2693,0.2487,0.2425,0.2379,0.2350,0.2319,0.2302,0.2274,0.2234,
      0.2231,0.2206,0.2189,0.2174,0.2155,0.2153,0.2117,0.2111,0.2111,0.2084,
      0.2071,0.2074,0.2049,0.2056,0.2037]
# plotting the line 1 points 
plt.plot(x1, y1, label = "Training MAE")
  
# line 2 points
x2 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]
y2 = [0.2869,0.2531,0.2471,0.2403,0.2470,0.2328,0.2405,0.2414,0.2218,0.2272,
      0.2267,0.2375,0.2354,0.2254,0.2406,0.2228,0.2160,0.2352,0.2136,0.2245,
      0.2089,0.2240,0.2191,0.2136,0.2107]
# plotting the line 2 points 
plt.plot(x2, y2, label = "Validation MAE")
  
# naming the x axis
plt.xlabel('Epochs')
# naming the y axis
plt.ylabel('Mean Absolute Error')
# giving a title to my graph
plt.title('CapsNet training and validation MAE')
  
# show a legend on the plot
plt.legend()
  
# function to show the plot
plt.show()