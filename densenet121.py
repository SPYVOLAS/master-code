# -*- coding: utf-8 -*-
"""DenseNet121.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cRxpLA5qG6UWT06HfvkPPc190WVKuzM-
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import cv2
from PIL import Image
import os
from glob import glob
from sklearn.preprocessing import LabelEncoder
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import pickle
from scipy import stats
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
# %matplotlib inline
import h5py
import tensorflow as tf
import keras
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
import keras.layers as layers
from keras.utils.np_utils import to_categorical
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization
from keras import backend as K
from keras.callbacks import ModelCheckpoint
from tensorflow.keras.optimizers import Adam

train_data = "/content/drive/MyDrive/split folder/ISIC_2019_train"
validation_data = "/content/drive/MyDrive/split folder/ISIC_2019_val"
test_data = "/content/drive/MyDrive/split folder/ISIC_2019_test"
train_metadata = pd.read_csv("/content/drive/MyDrive/ISIC_2019_train_metadata.csv")
validation_metadata =pd.read_csv("/content/drive/MyDrive/ISIC_2019_val_metadata.csv")
test_metadata = pd.read_csv("/content/drive/MyDrive/ISIC_2019_test_metadata.csv")

train_datagen = ImageDataGenerator(
        rescale=1/255.0,
        shear_range=0.3,
        zoom_range=0.3,
        rotation_range=90)

train_generator = train_datagen.flow_from_directory(
       "/content/drive/MyDrive/split folder/ISIC_2019_train",
        batch_size=32,
        target_size = (227, 227),
        shuffle = True,
        class_mode='categorical')

val_datagen = ImageDataGenerator(
        rescale=1/255.0,
        shear_range=0.3,
        zoom_range=0.3,
        rotation_range=90)

val_generator = val_datagen.flow_from_directory(
        "/content/drive/MyDrive/split folder/ISIC_2019_val",
        batch_size=10,
        shuffle = True,
        target_size = (227,227),
        class_mode='categorical')

test_datagen = ImageDataGenerator(rescale=1/255.0)

test_generator = test_datagen.flow_from_directory(
        "/content/drive/MyDrive/split folder/ISIC_2019_test",
        batch_size=1,
        target_size = (227,227),
        class_mode='categorical')

#DenseNet121 architecture
model2 = Sequential()
model2.add(tf.keras.applications.DenseNet121(
    include_top=False,
    weights="imagenet",
    pooling='avg',
    input_shape = (227, 227, 3)
))
model2.add(Dropout(0.5))
model2.add(Dense(2048, activation='relu'))
model2.add(Dropout(0.7))
model2.add(Dense(1024, activation='relu'))
model2.add(Dropout(0.7))
model2.add(Dense(8, activation='softmax'))

model2.layers[0].trainable = True

model2.summary()

checkpoint2 = ModelCheckpoint("/content/drive/MyDrive/best_model_DenseNet121.h5", monitor='val_acc', verbose=1,
    save_best_only=False, mode='max', save_freq="epoch")
callbacks_list=checkpoint

optimizer = Adam(learning_rate=0.0001)
model2.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy', "Precision", "Recall"])

history = model2.fit(train_generator, validation_data = val_generator, epochs=17, callbacks = [checkpoint2])

score = model1.evaluate(test_generator)

print('Test loss:', score[0])
print('Test accuracy:', score[1])
print('Test Precision:', score[2])
print('Test Recall:', score[3])

# line 1 points
x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
y1 = [0.5644,0.6623,0.6946, 0.7168,0.7307,0.7472,0.7591,0.7726,0.7842,0.7935,0.8075,0.8149,0.8232,0.8364,0.8390,0.8433,0.8586]
# plotting the line 1 points 
plt.plot(x1, y1, label = "training accuracy")
  
# line 2 points
x2 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
y2 = [0.6748,0.6792,0.6569,0.6839,0.7098,0.7327,0.7537,0.7454,0.7509,0.7616,0.7533,0.7568,0.7517,0.7724,0.7594,0.7695,0.7872]
# plotting the line 2 points 
plt.plot(x2, y2, label = "validation accuracy")
  
# naming the x axis
plt.xlabel('Epochs')
# naming the y axis
plt.ylabel('Accuracy')
# giving a title to my graph
plt.title('DenseNet121 training and validation accuracy')
  
# show a legend on the plot
plt.legend()
  
# function to show the plot
plt.show()

# line 1 points
x1 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
y1 = [1.3059,0.9739,0.8753, 0.8102,0.7616,0.7138,0.6826,0.6432,0.6079,0.5789,0.5476,0.5174,0.4918,0.4589,0.4522,0.4357,0.3967]
# plotting the line 1 points 
plt.plot(x1, y1, label = "training loss")
  
# line 2 points
x2 = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]
y2 = [0.9179,0.9161,1.0098,0.8442,0.8567,0.7331,0.6913,0.7215,0.6826,0.6569,0.6908,0.7077,0.7056,0.6440,0.6623,0.6498,0.5994]
# plotting the line 2 points 
plt.plot(x2, y2, label = "validation loss")
  
# naming the x axis
plt.xlabel('Epochs')
# naming the y axis
plt.ylabel('Loss')
# giving a title to my graph
plt.title('DenseNet121 training and validation loss')
  
# show a legend on the plot
plt.legend()
  
# function to show the plot
plt.show()

model2.save('/content/drive/MyDrive/DenseNet121.h5')
